---
editor: source
---
{{< pagebreak >}}

# Data Linkage in Manitoba

The internationally recognized Manitoba Population Research Data Repository is made possible through the integration of data across multiple domains, including health, education, social services, judicial affairs, and immigration.[@katz2019] This extensive collection of routinely-collected data with excellent population coverage of Manitoba residents, enables high-quality interdisciplinary research of topics highly relevant to Canadians, such as the social determinants of health and healthcare delivery patterns.  

Databases contained within the Repository are linked using a method known as “spine linkage.” In this approach, each dataset is linked to a central “spine dataset” (i.e., the Manitoba Health Insurance Registry), rather than performing pairwise linkages separately between all datasets.[@blake2023] After separately linking each Repository database to the Manitoba Health Insurance Registry to attach an encrypted Personal Health Identification Number (PHIN) field to each database, the encrypted PHIN is then used as the common unique identifier by researchers to join the de-identified datasets.[@katz2019] Spine linkage makes large data repositories feasible by significantly reducing the number of linkages required, which in turn reduces the disclosure of personally identifiable information.[@blake2023] However, a key limitation of spine linkage is the exclusion of individuals who are present in some data sources but not in the spine dataset. Consequently, the practice of performing spine linkage with the Manitoba Health Insurance Registry may adversely impact research based solely on non-health data sources. Studies focused on population subgroups without coverage through the Manitoba Health Services Insurance Plan (e.g., federally insured individuals, foreign students, temporary foreign workers with a work permit duration of less than one year) or with delayed coverage (e.g., new residents from other Canadian provinces) should carefully consider these limitations and changes in coverage requirements over time.[@govmb2023movingtomanitoba; @mchp2023term]   

In Manitoba, the responsibility for linking research data is shared among MCHP, Manitoba Health, and CHI. MCHP handles linkage between Repository databases and the Manitoba Health Insurance Registry, except for certain federally regulated data sources, which are managed by Manitoba Health. CHI and Manitoba Health share responsibilities for project-specific linkage services, such as the linking of clinical or survey datasets to the Manitoba Health Insurance Registry, enabling researchers to create enriched datasets by combining primary and routinely collected data. Additionally, CHI provides methodological guidance on data linkage practices and offers consultations to researchers and trainees on adjusting for linkage error in data analyses.  

To minimize the exposure of personal information in accordance with data privacy legislation, including the Personal Health Information Act (PHIA) and the Freedom of Information and Protection of Privacy Act (FIPPA),[@PHIA; @FIPPA] data linkage using identifiable information is performed by a small, trusted group of analysts from CHI, MCHP, and Manitoba Health. Following linkage, data is de-identified—by encrypting PHINs and removing names and addresses—before data is accessible to researchers within the MCHP secure data analytics environment.[@katz2019] Record similarity is commonly assessed using PHIN, given names, surnames, sex/gender, birthdate, and residential or mailing address including postal code. Even when PHIN is present in both data sources being linked, records are never joined solely on PHIN to account for potential data recording errors (e.g., incorrect PHINs being recorded) and to validate the PHINs that were collected.

{{< pagebreak >}}

# Background on Record Linkage {#sec-background}

Record linkage, also known as data linkage and entity resolution, is the task of determining which data records correspond to the same entity (i.e., the same person), and is used to deduplicate data by self-joining records within a single database and to create comprehensive datasets by bringing together person-level information from multiple sources. Record linkage techniques estimate the similarity between all possible pairs of records (i.e., the Cartesian product) by comparing the common fields present in both data sources. The similarity scores are then used to classify candidate record pairs as either matches (i.e., records belonging to the same individual) or non-matches (i.e., records belonging to different individuals). Given the potential for misclassification, the quality of linked data should be carefully assessed before proceeding with research data analysis.  

The objective of record linkage is to maximize linkage rate, the proportion of records in the left dataset linking to records in the right dataset, while minimizing false positive matches, which occur when records belonging to different individuals are incorrectly linked. Linkage algorithms commonly consist of multiple stages, with different techniques and parameter combinations selected in each pass to increase the amount of successfully matched record pairs. Identifying fields are combined differently across iterations to minimize data quality issues in select fields from adversely impacting overall linkage performance. Concluding each pass of a multi-step linkage algorithm, all predicted matches are removed from consideration prior to the next iteration.


## Blocking

Examining the similarity of all possible candidate record pairs is computationally infeasible with “big data,” defined as datasets too large to fit into computer memory. For instance, linking two datasets, each containing one million records, results in one trillion candidate record pairs---an impractical number to classify due to excessive computation time and memory requirements.[@christen2012] Blocking is a technique used to improve computational feasibility by reducing the search space of candidate record pairs. By constraining comparisons to candidate pairs with exact agreement on one or more identifiers, known as blocking keys, the most dissimilar pairs are filtered out and computational demand is significantly reduced. Blocking is a technique used to improve computational feasibility by reducing the search space of candidate record pairs. By constraining comparisons to candidate pairs with exact agreement on one or more identifiers, known as blocking keys, the most dissimilar pairs are filtered out and computational demand is significantly reduced. For example, using birth year as a blocking key means, only record pairs sharing the same birth year are considered, while all other potential matches are disregarded in that pass of the linkage algorithm. Although blocking aims to reduce the number of clear non-matches under examination, true matches may inadvertently be missed. To address this, multiple linkage passes can be performed with different blocking keys used at each stage. For example, after a pass with birth year as the blocking key, a subsequent pass might use birth month to capture pairs where the birth year was incorrectly recorded in either the left or right datasets. Blocking criteria is progressively less restrictive in subsequent passes since computational demand decreases as linked pairs from previous steps are set aside and removed from consideration.

## Record Linkage Approaches

There are two main linking approaches to record linkage: deterministic and probabilistic. With deterministic linkage, record pairs are classified as a match only if there is exact agreement among all considered fields. If any single identifier disagrees, even slightly, record pairs will remain unlinked. Secondly, deterministic matching assigns equal weight to all identifiers, ignoring differences in discriminative power, which is the effectiveness of a particular field to differentiate between matches and non-matches. For example, when deterministically linking two records based on surname, birth year, and sex, both records must exactly match on all three fields to be considered a match. However, this simplistic approach does not consider that surname has stronger discriminative ability than the other two fields, due to the relatively low frequency of most surnames within a dataset. In contrast, candidate record pairs agree on sex approximately 50% of the time, even among true non-matches, resulting in poor discriminative power. In this example, we may wish to classify record pairs as matches even if they disagree on sex, providing surnames are sufficiently similar. Probabilistic matching is a more robust approach that adjusts for discriminative power and allows record pairs to be classified as matches even when there is disagreement among some of the identifying fields under consideration.  

Linkage algorithms commonly consist of one or more deterministic passes, typically yielding the majority of matches in a dataset, before multiple probabilistic linkage steps are used to further increase linkage rate. The more stringent matching criteria inherent in deterministic approaches leads to higher confidence that predicted links represent true matches. In both deterministic and probabilistic approaches, extensions can be incorporated to increase resiliency against data recording errors. Approximate string matching techniques can be incorporated to account for spelling variations in given names (e.g., Meghan and Megan), abbreviations in residential addresses (e.g., Avenue vs. Ave.), and data recording errors such as postal codes entered as R3E 0T8 instead of R3E 0T6. The Jaro-Winkler string similarity measure2 is often used for this purpose. Additionally, acceptance ranges can increase flexibility when matching numeric fields, such as allowing birthdates to differ by plus or minus one week.

## Probabilistic Linkage

Probabilistic linkage is commonly performed achieved using the Fellegi-Sunter model where record similarity is estimated through the summation of log-likelihood ratios of two conditional probabilities, known as M (for matched) and U (for unmatched) probabilities.[@fellegisunter] Separate log-likelihood ratios, known as partial match weights, are calculated for each identifying field under consideration. The M probability is defined as the probability of field values agreeing, given that record pairs refer to the same entity (i.e., a true match); whereas the U probability is the probability of field values agreeing, given that record pairs refer to different entities (i.e., a true non-match). The M and U probabilities for each identifier may be manually specified, calculated based on observed frequencies in the data being linked, or more commonly, estimated with unsupervised learning using the Expectation-Maximization algorithm.[@winkler2000] The partial match weights are summed to estimate a total match weight for each candidate record pair meeting blocking constraints. The match weight, which is unbounded, can be converted to a posterior probability with values scaled between 0 and 1.[@enamorado2019] The match weights or posterior probabilities are then used to classify record pairs as matches if they exceed a chosen threshold. 

The traditional Fellegi-Sunter approach requires two thresholds to be set: record pairs with match weights below the lower threshold are classified as non-matches, those above the higher threshold are classified as matches, while candidate pairs with weights between these thresholds undergo manual review. However, this conservative approach is largely impracticable when linking large databases, and instead, a single-threshold approach is commonly employed. While a single-threshold approach improves efficiency by omitting the clerical review of potential matches, the uncertainty of the intermediate match weights can lead to increased rates of misclassification. In cases where a record in the left dataset has multiple pairs on the right dataset with similarity scores above the acceptance threshold, the pair with the highest match weight is selected.

## Linkage Error

Merging records from different sources may lead to two types of errors: 1) incorrectly linking records that belong to two different individuals (i.e., false positive matches), and 2) missed matches between records that belong to the same individual (i.e., false negatives). The linkage errors, which may reduce data representativeness, can arise from data entry errors, such as misspelled names; incomplete information, such as missing PHIN; and transient information, such as surname and residential address, that is recorded inconsistently across data sources. Non-random linkage error can lead to selection bias in the resulting linked data. For example, women who change their surname upon marriage may be disproportionately excluded if data capture dates differ considerably between data sources and maiden name is not available in the data. Similarly, individuals with high residential mobility may be disproportionately excluded if residential address is used for linkage but captured inconsistently across databases. Differential linkage error can be assessed by examining linkage rates stratified by sociodemographic characteristics. In situations where a unique personal identifier, such as PHIN, is available in both data sources, it may be used as the ground truth to evaluate classification accuracy.


{{< pagebreak >}}

# Methods {#sec-methods}

We used an iterative, multistage approach to link the records from `r params$left_dataset_name` to records in `r params$left_dataset_name`.

## Data Pre-processing

The steps taken to clean and standardize the data rely on its cleanliness and availability of fields.

All punctuation was removed from non-numeric fields, and characters were converted to a common case. To reduce name variation, names with common values were given a standard form: nicknames were converted to full given names (e.g., Bill =\> William); and spelling variations were converted to standard forms (e.g., Haley, Hailey, Hailee =\> Hailey). \[Similarly, to reduce address variation, abbreviations were expanded to their original forms (e.g., Rd or Rd. =\> Road).\] Fields with multiple attributes, such as name fields containing both primary (i.e., first name) and secondary (i.e., middle name) given names, were split into separate fields. Date fields were divided into day, month, and year fields by analyzing the date format (e.g., DD/MM/YYYY, MM/DD/YYYY, YYYY-MM-DD, etc.) and separating accordingly.

Categorical variables, such as sex/gender or ethnicity, were given a common set of standard values across the two datasets\^(reference datastan?). For example, if gender is categorized as Male = 1, Female = 2, Non-binary = 3, Gender fluid = 4, and Other = 5 in the left dataset, and as Male = M, Female = F, and Other = X in the right dataset, the values would be converted to the common categories. Since the right dataset has only three categories, the left dataset’s values would need to be adjusted to match. Specifically, Male = 1 would be converted to M, Female = 2 would be converted to F, and Non-binary = 3, Gender fluid = 4, and Other = 5 would be converted to X\^(reference datastan?). (where should the reference go?)

### Missing Data Imputation

Haven't figured out how to display missing data imputation yet so unsure if this should be included: Missing data was imputed by inferring sex/gender from primary given name---the first name in the provided name field. In cases where data elements were combined into single fields, such as postal codes being appended to address fields, regular expressions were used to separate the data elements and impute the missing data.

## Linkage Algorithm

Linkage was performed using the `r params$linkage_package` package in R (version `r params$linkage_package_version`). Records were linked through an iterative process using a combination of deterministic and probabilistic steps`r if (!is.null(algorithm_summary_table)) " (@tbl-algorithm_summary)"`. For probabilistic steps, the Fellegi-Sunter model @fellegisunter with extensions were used to generate match weights for each candidate record pair that met blocking constraints.\
These extensions included:

a)  The Expectation-Maximization algorithm for the unsupervised learning of M and U conditional probabilities.[@winkler2000]  

b)	The Jaro-Winkler similarity metric for approximate string matching.[@jarowinkler]  

c)	Adjusting identifier weights for observed frequencies (i.e., common vs. rare values). For example, higher weights were assigned for matching on less common names (e.g., Barret) than more frequent values (e.g., John).

d)  Total match weights were scaled to a standard range: \[0,1\].

e)  Blocking to filter candidate record pairs and reduce computational demand time and memory requirements.

f)	A single acceptance threshold was used instead of the traditional two-threshold approach

Different sets of blocking and matching variables`r if (!is.null(algorithm_summary_table)) " (@tbl-algorithm_summary)"` were selected for each iteration with the aim of considering every possible record pair. In each iteration, the candidate record pairs were all possible combinations of record pairs that remained after blocking filtered out those that did not meet the blocking criteria.

Initially, a deterministic pass was conducted, followed by multiple probabilistic passes. During each probabilistic pass, match weights were computed for each matching variable across all candidate record pairs, summed, and then normalized to produce the final match weight for each pair. An acceptance threshold was selected by examining the match weights of candidate record pairs, identifying weights that appeared to represent both matches and non-matches, and setting it between these intermediate values. Candidate record pairs were classified as matches if their match weight exceeded the chosen threshold and was the highest among all match weights for that record. If a record was involved in multiple pairs with the same highest match weight exceeding the threshold, the pair with the most recent data was selected and classified as a match.

Match weights for string-matching variables, such as surname, were computed using the Jaro-Winkler string distance metric. A Jaro-Winkler acceptance threshold was chosen to classify whether two strings should be considered the same or different. If the distance metric exceeded the threshold, the pair was assigned a weight of 1 to indicate they were considered the same; otherwise, they were assigned a weight of 0.

The pre-processing step introduced new variables that expanded our ability to make comparisons beyond our initial capability. Non-English language names follow different ordering or formatting conventions compared to English language names. Therefore, when multiple given names were present, separating them enabled us to compare all given names with the primary given name of the current record, enhancing the likelihood of a match. To address data entry errors where month and day fields may have been mistakenly interchanged, separating the date fields enabled us to compare days directly with months.

Following each linkage step, matched record pairs were removed from contention before subsequent iterations were performed.

## Linkage Algorithm Evaluation

This data linkage quality report was generated in R using the linkrep package (version `r params$linkrep_package_version`) to facilitate assessments of linked data quality.[@linkrep] Linkage rates were stratified by sociodemographic characteristics (@tbl-linkage_rates) to enable an examination of the algorithm’s  consistency across demographic groups and identify potential selection bias.`r if(!is.null(linkage_rates_over_time_plot)) " To assess how changes in data capture may have affected linkage rates over time, a histogram is provided showing linkage rate trends over time (@fig-linkage_rate_dist)."`  

`r if(!is.null(params$ground_truth)) "::: {.content-visible}" else "::: {.content-hidden}"`
Links predicted by the probabilistic linkage algorithm were evaluated against `r params$ground_truth` as the ground truth`r if(!is.null(performance_measures_table)) " (@tbl-performance_measures_tbl)"`. Classification accuracy was estimated using the subset of records from `r params$left_dataset_name` that had non-missing values for the gold standard field, `r params$ground_truth`, before executing the linkage algorithm.   

Classification performance was evaluated using the following metrics:   

PPV = $\frac{TP}{TP + FP}$

NPV = $\frac{TN}{TN + FN}$

Sensitivity = $\frac{TP}{TP + FN}$

Specificity = $\frac{TN}{TN + FP}$

F1-Score = $2 \cdot \frac{PPV \cdot Sensitivity}{PPV + Sensitivity}$

where $TP$ = true positive, $TN$ = true negative, $FP$ = false positive, and $FN$ = false negative
:::
